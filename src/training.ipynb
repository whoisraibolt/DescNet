{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aVwPd_i_cnSE"},"outputs":[],"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","\"\"\"\n","Descriptor Convolutional Neural Network\n","\"\"\"\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"VweLrTjCcnSG"},"source":["# Install packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvtsU5ZPcnSH"},"outputs":[],"source":["! pip install nvgpu\n","! pip install py-cpuinfo\n","! pip install timer\n","! python -m pip install psutil==5.7.2 --user"]},{"cell_type":"markdown","metadata":{"id":"8N8reeJJ2JgL"},"source":["# Check if is running on Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArncU5zVmQnJ"},"outputs":[],"source":["use_colab = 'google.colab' in str(get_ipython())\n","\n","if use_colab:\n","    # Define base path\n","    BASE_PATH = '/content/gdrive/My Drive/Colab Notebooks/DESC-NET/src/'\n","\n","    # Import Libraries from colab\n","    from google.colab import drive\n","    from google.colab import output\n","    import IPython\n","    \n","    # Mount Google Drive for fast, responsible access to files\n","    drive.mount('/content/gdrive')\n","    \n","    message_use_colab = '[INFO] Running on Colab:\\n'\n","else:\n","    message_use_colab = '[INFO] Not running on Colab:\\n'\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"L2oOq4rC5mxd"},"source":["# Colab Runtime to prevent from disconnecting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOqAfSLG5mxe"},"outputs":[],"source":["if use_colab:\n","    display(IPython.display.Javascript('''\n","    function ClickConnect(){\n","        btn = document.querySelector(\"colab-connect-button\")\n","        if (btn != null){\n","          console.log(\"Click colab-connect-button\"); \n","          btn.click() \n","        }\n","        \n","        btn = document.getElementById('ok')\n","        if (btn != null){\n","          console.log(\"Click reconnect\"); \n","          btn.click() \n","        }\n","      }\n","        \n","    setInterval(ClickConnect, 60000)'''))\n","else:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"dnnzwRnhQ1Ws"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_N2CiyBfG799"},"outputs":[],"source":["from PIL import Image\n","from tensorflow.keras.utils import to_categorical\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import model_from_json\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad\n","from tensorflow.keras.utils import CustomObjectScope\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.metrics import TopKCategoricalAccuracy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import cv2 as cv\n","import glob\n","import json\n","import numpy as np\n","import os\n","import pickle\n","import random\n","import tensorflow as tf\n","import time\n","import timeit\n","import zipfile"]},{"cell_type":"markdown","metadata":{"id":"5DjDzZZ5SVh9"},"source":["# Import Learning Rate Schedulers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXJPJGuFSW4b"},"outputs":[],"source":["if use_colab:\n","    SCHEDULERS = 'lr_schedulers.zip'\n","\n","    SCHEDULERS_PATH =  \"/\".join([BASE_PATH, SCHEDULERS])\n","\n","    zip_object = zipfile.ZipFile(file = SCHEDULERS_PATH,\n","                                mode = 'r')\n","\n","    zip_object.extractall()\n","\n","    zip_object.close\n","\n","from lr_schedulers.clr_callback import CyclicLR\n","from lr_schedulers.learning_rate_schedulers import StepDecay"]},{"cell_type":"markdown","metadata":{"id":"2GePsfB2Hkx9"},"source":["# Import Custom Libraries"]},{"cell_type":"markdown","metadata":{"id":"dPN7veuDJRcj"},"source":["# ImportError: cannot import name 'bytes2human' from 'psutil._common' (/usr/local/lib/python3.7/dist-packages/psutil/_common.py)\n","\n","Just go to Runtime >>> Reset all runtimes..."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"CIV2aXEU-6vJ"},"outputs":[],"source":["# To import and use the custom imports, the folder need\n","# to be in se same directory to de file (in colab) \n","if use_colab:\n","    # Unzip in Colab Workspace\n","    UTILITIES = 'utilities.zip'\n","\n","    UTILITIES_PATH =  \"/\".join([BASE_PATH, UTILITIES])\n","\n","    zip_object = zipfile.ZipFile(file = UTILITIES_PATH,\n","                                mode = 'r')\n","\n","    zip_object.extractall()\n","\n","    zip_object.close\n","\n","from utilities.dataset import(#manipulate_pandas,\n","                              create_dataset\n",")\n","\n","from utilities.descriptors import find_detector_or_descriptor\n","\n","from utilities import global_variables\n","\n","from utilities.logfile import(close_logfile,\n","                              open_logfile,\n","                              print_descriptor_initialized_info,\n","                              print_detector_initialized_info,\n","                              print_system_info,\n","                              print_packages_info\n",")\n","\n","from utilities.timer import Timer\n","\n","from utilities.visualizations import(#save_dataset_distribution,\n","                                     save_architecture_visualization,\n","                                     save_model_accuracy_history,\n","                                     save_model_loss_history,\n","                                     save_confusion_matrix,\n",")\n","\n","\n","from utilities.local_feature_detection import local_feature_detection\n","\n","from utilities.local_descriptor_convolution import * # TODO: Arrumar e importar todos... depois...\n","\n","from utilities.residual_neural_network import ResNet\n","\n","from utilities.model_functions import(training,\n","                                      evaluate,\n","                                      predict)"]},{"cell_type":"markdown","metadata":{"id":"7PGZQ1XMJyEZ"},"source":["# Import config.json\n","## Used to load the user configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjznLArrJyRY"},"outputs":[],"source":["if use_colab:\n","    # Unzip in Colab Workspace\n","    JSON = 'config.zip'\n","\n","    JSON_PATH =  \"/\".join([BASE_PATH, JSON])\n","\n","    zip_object = zipfile.ZipFile(file = JSON_PATH,\n","                                 mode = 'r')\n","\n","    zip_object.extractall()\n","\n","    zip_object.close \n","\n","JSON_PATH = 'config.json'\n","\n","# Load the user configurations\n","with open(JSON_PATH, encoding='utf8') as f:    \n","    config = json.load(f)"]},{"cell_type":"markdown","metadata":{"id":"Pns3fREbcnSL"},"source":["# Config variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oY7Y_hy4cnSM"},"outputs":[],"source":["# Stores the dataset's name\n","DATASET = config['dataset']\n","\n","try:\n","    assert(DATASET == 'MNIST' or\n","           DATASET == 'JAFFE' or\n","           DATASET == 'Extended-CK+' or\n","           DATASET == 'CIFAR-10' or\n","           DATASET == 'CIFAR-100' or\n","           DATASET == 'FEI' or\n","           DATASET == 'FER-2013' or\n","           DATASET == 'ILSVRC-2017')\n","except AssertionError as e:\n","    raise(AssertionError('`DATASET` cannot be different from MNIST or JAFFE or Extended-CK+ or CIFAR-10 or CIFAR-100 or FEI or FER-2013 or ILSVRC-2017'))\n","\n","# Path of training-set\n","DATA_TRAIN_IMAGES = \"/\".join([config['dataset'], config['data_train_images']])\n","\n","# Path of test-set\n","DATA_TEST_IMAGES = \"/\".join([config['dataset'], config['data_test_images']])\n","\n","# Stores the detector's name\n","DETECTOR = config['detector']\n","\n","try:\n","    assert(DETECTOR == 'SIFT' or\n","           DETECTOR == 'SURF' or\n","           DETECTOR == 'KAZE' or\n","           DETECTOR == 'ORB' or\n","           DETECTOR == 'BRISK' or\n","           DETECTOR == 'AKAZE')\n","except AssertionError as e:\n","    raise(AssertionError('`DETECTOR` cannot be different from SIFT or SURF or KAZE or ORB or BRISK or AKAZE'))\n","\n","# Stores the descriptor's name\n","DESCRIPTOR = config['descriptor']\n","\n","try:\n","    assert(DESCRIPTOR == 'SIFT' or\n","           DESCRIPTOR == 'SURF' or\n","           DESCRIPTOR == 'KAZE' or\n","           DESCRIPTOR == 'BRIEF' or\n","           DESCRIPTOR == 'ORB' or\n","           DESCRIPTOR == 'BRISK' or\n","           DESCRIPTOR == 'AKAZE' or\n","           DESCRIPTOR == 'FREAK')\n","except AssertionError as e:\n","    raise(AssertionError('`DESCRIPTOR` cannot be different from SIFT or SURF or KAZE or BRIEF or ORB or BRISK or AKAZE or FREAK'))\n","\n","# Stores the reducer's name\n","#REDUCER = config['reducer']\n","\n","# Stores the architecture's name of CNN\n","ARCHITECTURE = config['architecture']\n","\n","try:\n","    assert(ARCHITECTURE == 'DescNet-50' or\n","           ARCHITECTURE == 'DescNet-101' or\n","           ARCHITECTURE == 'DescNet-152' or\n","           ARCHITECTURE == 'ResNet-50' or\n","           ARCHITECTURE == 'ResNet-101' or\n","           ARCHITECTURE == 'ResNet-152')\n","except AssertionError as e:\n","    raise(AssertionError('`ARCHITECTURE` cannot be different from DescNet-50 or DescNet-101 or DescNet-152 or ResNet-50 or ResNet-101 or ResNet-152'))\n","\n","# Store's desc block if used\n","USE_DESC_BLOCK = config['use_desc_block']\n"," \n","# Define base path\n","if not use_colab:\n","    BASE_PATH = config['main_path']\n","    \n","# Output path\n","OUTPUT = \"/\".join(['Outputs', config['dataset'], config['architecture'], config['descriptor']])"]},{"cell_type":"markdown","metadata":{"id":"g1Mt-lUDcnSN"},"source":["# Initializing global variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vf6_sdxYcnSN"},"outputs":[],"source":["global_variables.initialize()\n","\n","# Simple line to difide dome steps of this project\n","global_variables.LINE\n","\n","# Absolute output path\n","global_variables.OUTPUT_PATH = \"/\".join([BASE_PATH, OUTPUT])"]},{"cell_type":"markdown","metadata":{"id":"tzrqquxtcnSO"},"source":["# Create Output path if not exists"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVe9_p4gcnSO"},"outputs":[],"source":["try:\n","    os.makedirs(name = global_variables.OUTPUT_PATH)\n","    print('\\n[INFO]: `global_variables.OUTPUT_PATH` does not exist... creating...')\n","except FileExistsError:\n","    # global_variables.OUTPUT_PATH already exists\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"-Nir-La4cnSO"},"source":["# Open logfile to start write"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlBdPvj8cnSO"},"outputs":[],"source":["open_logfile()"]},{"cell_type":"markdown","metadata":{"id":"VmwINmKdcnSO"},"source":["# Print if is running or not on Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0OcPCtnicnSP"},"outputs":[],"source":["print(message_use_colab, file = global_variables.LOGFILE)"]},{"cell_type":"markdown","metadata":{"id":"8R4rf0wJcnSP"},"source":["# Print current CPU, GPU, and RAM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aZXrSNJbcnSP"},"outputs":[],"source":["print_system_info()"]},{"cell_type":"markdown","metadata":{"id":"O1U-_4O0cnSP"},"source":["# Set current Distribution Strategy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m2GL9Lwjkrdn"},"outputs":[],"source":["if use_colab:\n","    # Try to run on TPU\n","    # Detect hardware, return appropriate distribution strategy\n","    try:\n","        # Get a handle to the attached TPU\n","        TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","\n","        # print('Running on TPU', tpu.cluster_spec().as_dict()['worker'])\n","    except ValueError:\n","        TPU = None\n","\n","    if TPU:\n","        # Connect to the TPU handle \n","        tf.config.experimental_connect_to_cluster(TPU)\n","\n","        # And initialise it\n","        tf.tpu.experimental.initialize_tpu_system(TPU)\n","\n","        # Set the distribution strategy\n","        strategy = tf.distribute.experimental.TPUStrategy(TPU)\n","        \n","        print(f'[INFO] TPU Strategy adopted:\\n', file = global_variables.LOGFILE)\n","        \n","        print(f'[INFO] Number of devices: {strategy.num_replicas_in_sync}\\n', file = global_variables.LOGFILE)\n","        \n","        print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)\n","        \n","elif tf.config.list_physical_devices('GPU'):\n","    strategy = tf.distribute.MirroredStrategy()\n","    \n","    print(f'[INFO] GPU Strategy adopted:\\n', file = global_variables.LOGFILE)\n","    \n","    print(f'[INFO] Number of devices: {strategy.num_replicas_in_sync}\\n', file = global_variables.LOGFILE)\n","    \n","    print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)\n","\n","# Use default strategy\n","else:\n","    strategy = tf.distribute.get_strategy()\n","    \n","    print(f'[INFO] Default Strategy adopted:\\n', file = global_variables.LOGFILE)\n","    \n","    print(f'[INFO] Number of devices: {strategy.num_replicas_in_sync}\\n', file = global_variables.LOGFILE)\n","    \n","    print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)"]},{"cell_type":"markdown","metadata":{"id":"JY2peVnscnSQ"},"source":["# Print Python, OpenCV, TensorFlow, and Keras versions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxajC5KqcnSQ"},"outputs":[],"source":["print_packages_info()"]},{"cell_type":"markdown","metadata":{"id":"3lEXPSBopYFJ"},"source":["# Unzip outside Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulosWBTvS4UQ"},"outputs":[],"source":["DATASET_PATH = '/'.join([BASE_PATH, 'Datasets', DATASET + '.zip'])\n","\n","zip_object = zipfile.ZipFile(file = DATASET_PATH,\n","                             mode = 'r')\n","\n","zip_object.extractall('./')\n","\n","zip_object.close"]},{"cell_type":"markdown","metadata":{"id":"23viE7EwO1TV"},"source":["# Dimensions of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PIO3sejG79_"},"outputs":[],"source":["# Classes info\n","CLASSES = os.listdir(DATA_TRAIN_IMAGES)\n","\n","for i in range(1):\n","    TEST_FOLDER = '/'.join([DATA_TRAIN_IMAGES, CLASSES[0]])\n","    \n","    image_name = random.choice(os.listdir(TEST_FOLDER))\n","\n","    image_path = \"/\".join([TEST_FOLDER, image_name])\n","\n","    image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n","\n","    # Images size\n","    IMAGE_HEIGHT, IMAGE_WIDTH = image.shape\n","\n","# Images are stored in one-dimensional arrays of this length\n","IMAGE_SIZE_FLAT = IMAGE_HEIGHT * IMAGE_WIDTH\n","\n","# Tuple with height and width of images used to reshape arrays\n","IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n","\n","# Number of classes\n","N_CLASSES = len(CLASSES)\n","\n","# Number of colour channels for the images\n","# Channels mean number of primary colors   \n","if image.ndim == 2:\n","    N_CHANNELS = 1\n","elif image.ndim == 3:\n","    N_CHANNELS = image.shape[-1]"]},{"cell_type":"markdown","metadata":{"id":"UL4x_krNcnSS"},"source":["# Create Dataset from folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nGopGbgcnSS"},"outputs":[],"source":["# Returns the values of the function for images_set, labels_set on train-set\n","x_train, y_train = create_dataset(DATA_TRAIN_IMAGES, IMAGE_SHAPE = IMAGE_SHAPE)\n","\n","target_dict_train = {k: v for v, k in enumerate(np.unique(y_train))}\n","\n","y_train = [target_dict_train[y_train[i]] for i in range(len(y_train))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAxjTqZjcnSS"},"outputs":[],"source":["# Returns the values of the function for images_set, labels_set on test-set\n","x_test, y_test = create_dataset(DATA_TEST_IMAGES, IMAGE_SHAPE = IMAGE_SHAPE)\n","\n","target_dict_test = {k: v for v, k in enumerate(np.unique(y_test))}\n","\n","y_test = [target_dict_test[y_test[i]] for i in range(len(y_test))]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4Xb9NPRcnSS"},"outputs":[],"source":["# so we produce 3D matrix. But we require a 4D matrix to use tf.nn.conv2d for the convolutional layer. We increase the dimensions using tf.expand_dims.\n","# Só mudar explicação mudando para função do keras e expand_dims do numpy\n","\n","# A 3D matrix was produced\n","# However, to use tf.nn.conv2d for the convolutional layer, a 4D matrix is needed,\n","# So tf.expand_dims is used to increase the dimension in the matrix\n","x_train = np.expand_dims(x_train, axis = 0)\n","\n","x_test = np.expand_dims(x_test, axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFiiqZRacnST"},"outputs":[],"source":["# Before we jump into convolution, It’s necessary to know what will be the size of our filter\n","# matrix(which will slide over input data in the covolutional layer), it has to be a 4D tensor.\n","# num_filters and filter size are the hyperparameters you need to declare as per the requirements.\n","# The number of filters per filter size is num_filters . And often we use more than one filter\n","# size for convolution. For image data we can define it like:\n","\n","#filter_shape = [filter_size num_input_channels 1 num_filters]\n","\n","# Now we have to transpose this Tensor\n","# Só mudar explicação mudando para função do keras e expand_dims do numpy\n","\n","# Before performing the convolution operation, it is necessary to know how\n","# the shape of the kernel Tensor must be:\n","# `filter_shape` = [filter_height, filter_width, in_channels, out_channels]\n","\n","# So far, the shape of `feature_weights` is:\n","# `feature_weights` = [out_channels, filter_height, filter_width, in_channels]\n","# print(x_train.shape)\n","\n","x_train = np.transpose(x_train, (1, 2, 3, 0))\n","\n","x_test = np.transpose(x_test, (1, 2, 3, 0))"]},{"cell_type":"markdown","metadata":{"id":"oTdcsEQ2cnST"},"source":["# One-Hot Encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f65wYMdicnST"},"outputs":[],"source":["# One-Hot Encode\n","y_train = to_categorical(y_train)\n","\n","y_test = to_categorical(y_test)"]},{"cell_type":"markdown","metadata":{"id":"p2dEMeCicnST"},"source":["# Use a Manual Verification Dataset\n","## Split into sets for training and validation\n","## The validation-set will be used to validate the performance of the model (Cross-Validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4lKKuvX4cnST"},"outputs":[],"source":["# Common reasons used:\n","# train 60%, val e test 20%\n","# train 70%, val e test 15%\n","# train 80%, val e test 10%\n","x_train, x_val, y_train, y_val = train_test_split(x_train,\n","                                                  y_train,\n","                                                  test_size = 0.1,\n","                                                  random_state = 41)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwL9BilScnST"},"outputs":[],"source":["# TODO: Criar uma função e jogar no módulo LOGFILE\n","\n","print(f'[INFO] {(DATASET)} Dataset information:\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of Classes: {N_CLASSES}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of Channels: {N_CHANNELS}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of images in training-set: {len(x_train)}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of images in validation-set: {len(x_val)}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of images in test-set: {len(x_test)}\\n', file = global_variables.LOGFILE)\n","\n","print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)"]},{"cell_type":"markdown","metadata":{"id":"AoQqskH9cnSU"},"source":["# Save all sets as Numpy for easy future use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tcNv-_2BcnSU"},"outputs":[],"source":["# Training-set\n","np.save('/'.join([global_variables.OUTPUT_PATH, 'x_train']), x_train)\n","np.save('/'.join([global_variables.OUTPUT_PATH, 'y_train']), y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"msnZQzmOcnSU"},"outputs":[],"source":["# Evaluation-set\n","np.save('/'.join([global_variables.OUTPUT_PATH, 'x_val']), x_val)\n","np.save('/'.join([global_variables.OUTPUT_PATH, 'y_val']), y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RhnP5DcmcnSU"},"outputs":[],"source":["# Test-set\n","np.save('/'.join([global_variables.OUTPUT_PATH, 'x_test']), x_test)\n","np.save('/'.join([global_variables.OUTPUT_PATH, 'y_test']), y_test)"]},{"cell_type":"markdown","metadata":{"id":"GUyxyFvfcnSU"},"source":["# Initiate detector and descriptor selected"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ya6JL5M1cnSU"},"outputs":[],"source":["if USE_DESC_BLOCK == 'True':\n","    detector_initialized = find_detector_or_descriptor(DETECTOR)\n","\n","    descriptor_initialized = find_detector_or_descriptor(DESCRIPTOR)"]},{"cell_type":"markdown","metadata":{"id":"1HqVhgo5cnSU"},"source":["# Print detector and descriptor selected"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEFcqIuDcnSV"},"outputs":[],"source":["if USE_DESC_BLOCK == 'True':\n","    print_detector_initialized_info(detector = detector_initialized)\n","\n","    print_descriptor_initialized_info(descriptor = descriptor_initialized)"]},{"cell_type":"markdown","metadata":{"id":"M5dJ893QcnSV"},"source":["# Model and Checkpoints data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7IQCIlz-cnSV"},"outputs":[],"source":["# Store and update epochs state\n","INIT_EPOCH_TRAIN = 0\n","\n","# Output path for model and checkpoints\n","OUTPUT_MODEL_N_CHECK = \"/\".join([config['dataset'], config['architecture'], config['descriptor']])\n","\n","# Where models are stored\n","MODEL_PATH = \"/\".join([BASE_PATH, 'Models', OUTPUT_MODEL_N_CHECK])\n","\n","# Stores model data and checkpoints\n","CHECKPOINT_PATH = \"/\".join([BASE_PATH, 'Pretrained', OUTPUT_MODEL_N_CHECK])\n","\n","try:\n","    os.makedirs(name = MODEL_PATH)\n","    print('\\n[INFO]: `MODEL_PATH` does not exist... creating...')\n","except FileExistsError:\n","    # PRE_TRAINED_PATH already exists\n","    pass\n","\n","try:\n","    os.makedirs(name = CHECKPOINT_PATH)\n","    print('\\n[INFO]: `CHECKPOINT_PATH` does not exist... creating...')\n","except FileExistsError:\n","    # OUTPUT_PATH already exists\n","    pass\n","\n","# Default name to save checkpoints\n","CHECKPOINT_FILENAME = os.path.join(CHECKPOINT_PATH, 'model_weights_improvement_{epoch:02d}_{val_acc:.2f}.h5')\n","\n","# Used to check if checkpoints exists\n","CHECK_CHECKPOINT_FILENAME = '/'.join([CHECKPOINT_PATH, 'model_weights_improvement_**_*.**.h5'])\n","\n","# TODO: Jogar essa função em algum lugar\n","# Help-function to get the initial epoch number from the checkpoint\n","def get_init_epoch_function(checkpoint_path):\n","    filename = os.path.basename(checkpoint_path)\n","    filename = os.path.splitext(filename)[0]\n","    \n","    init_epoch = filename.split(\"_\")[3]\n","    \n","    return int(init_epoch)"]},{"cell_type":"markdown","metadata":{"id":"JW5Et51PcnSV"},"source":["# Check if checkpoints exists"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-zC2qu4cnSV"},"outputs":[],"source":["# if true, get the last one\n","if len(glob.glob(CHECK_CHECKPOINT_FILENAME)) != 0:\n","        # List of files\n","        list_of_files = glob.glob(CHECK_CHECKPOINT_FILENAME)\n","\n","        # Get the last one checkpoint to load and continue from\n","        training_checkpoint = max(list_of_files, key = os.path.getmtime)\n","\n","        # Get the epoch number to continue from\n","        INIT_EPOCH_TRAIN = get_init_epoch_function(checkpoint_path = training_checkpoint)\n","\n","        print(f'[INFO] Training checkpoint found for epoch {INIT_EPOCH_TRAIN}. Will continue from that epoch\\n', file = global_variables.LOGFILE)\n","        \n","        print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)\n","\n","        load_from_checkpoint_train = True\n","else:\n","        print('[INFO] Training checkpoint not found. Will start from epoch 1\\n', file = global_variables.LOGFILE)\n","        \n","        print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)\n","        \n","        load_from_checkpoint_train = False"]},{"cell_type":"markdown","metadata":{"id":"8IMvmg2GcnSW"},"source":["# Local Feature Detection (LFD) Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0A6VM0-mcnSW"},"outputs":[],"source":["if USE_DESC_BLOCK == 'True':\n","    local_feature_detection(path_dir = DATA_TRAIN_IMAGES,\n","                            descriptor = DESCRIPTOR,\n","                            detector_initialized = detector_initialized,\n","                            descriptor_initialized = descriptor_initialized)\n","    \n","    print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)"]},{"cell_type":"markdown","metadata":{"id":"51HrQg5McnSW"},"source":["# Local Descriptor Convolution (LDC) Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrJiLyWfcnSW"},"outputs":[],"source":["with Timer() as timer:\n","    # Restore checkpoint\n","    if load_from_checkpoint_train:\n","        print(f'[INFO] Building Model:\\n', file = global_variables.LOGFILE)\n","\n","        json_file = '/'.join([MODEL_PATH, config['architecture'] + '.json'])\n","\n","        json_file = open(json_file, 'r')\n","\n","        loaded_model_json = json_file.read()\n","\n","        json_file.close()\n","\n","        if USE_DESC_BLOCK == 'True':\n","            with CustomObjectScope({'DescConv2D': DescConv2D}):\n","                    # Load Model\n","                    model = model_from_json(loaded_model_json)\n","                    \n","                    # Load Weights\n","                    model.load_weights(training_checkpoint)\n","\n","        else:\n","            model = load_model(training_checkpoint) # TODO Talves mudar aqui também... testar com ResNet\n","    else:\n","      print(f'[INFO] Building Model:\\n', file = global_variables.LOGFILE)\n","\n","      model = ResNet(n_res = ARCHITECTURE, input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS), classes = N_CLASSES)\n","\n","print(f'[INFO] Time: {timer}\\n', file = global_variables.LOGFILE)\n","\n","model.summary(print_fn = lambda x: global_variables.LOGFILE.write(f'{x}\\n'))\n","\n","#print(f'\\n', file = global_variables.LOGFILE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMoinC-CcnSW"},"outputs":[],"source":["# Optimizer\n","# Printar esses dados também\n","opt = Adam(lr = 0.001,\n","           beta_1 = 0.9,\n","           beta_2 = 0.999,\n","           epsilon = 1e-8)\n","\n","# if N_CLASSES == 2:\n","#    loss = 'sparse_categorical_crossentropy'\n","# else:\n","loss = 'categorical_crossentropy'\n","\n","def RMSE(y_true, y_pred):\n","    return K.sqrt(K.mean(K.square(y_pred - y_true), axis = -1))\n","\n","options = tf.compat.v1.RunOptions(report_tensor_allocations_upon_oom = True)\n","metadata = tf.compat.v1.RunMetadata()\n","\n","model.compile(loss = loss,\n","              optimizer = opt,\n","              #metrics = ['accuracy'],\n","              metrics = [RMSE, 'accuracy', 'top_k_categorical_accuracy'],\n","              options = options,\n","              run_metadata = metadata)"]},{"cell_type":"markdown","metadata":{"id":"YzZuT5mPcnSX"},"source":["# Save Model Architecture Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wa913sTHcnSX"},"outputs":[],"source":["save_architecture_visualization(model = model)"]},{"cell_type":"markdown","metadata":{"id":"zRB6bBkWcnSX"},"source":["# Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2aPEix3cnSX"},"outputs":[],"source":["# if USE_DESC_BLOCK:\n","h5_file = '/'.join([MODEL_PATH, ARCHITECTURE + '.h5'])\n","json_file = '/'.join([MODEL_PATH, ARCHITECTURE + '.json'])\n","# else:\n","#    h5_file = '/'.join([MODEL_PATH, ARCHITECTURE + '.h5'])\n","#    json_file = '/'.join([MODEL_PATH, ARCHITECTURE + '.json'])\n","    \n","# Save Model Architecture to H5\n","model.save(h5_file)\n","\n","# Save Model Architecture to JSON\n","model_json = model.to_json()\n","\n","with open(json_file, \"w\") as output_file:\n","    output_file.write(model_json)"]},{"cell_type":"markdown","metadata":{"id":"lan_abJecnSX"},"source":["# Define callbacks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7I7-hqccnSX"},"outputs":[],"source":["lr_reduce = ReduceLROnPlateau(monitor = 'val_acc',\n","                              factor = 0.9,\n","                              patience = 1,\n","                              verbose = 1)\n","\n","# Avoid overfitting \n","early_stop = EarlyStopping(monitor = 'val_acc',\n","                           min_delta = 0.001,\n","                           patience = 15,\n","                           verbose = 1,\n","                           mode = 'max',\n","                           restore_best_weights = True)\n","\n","\n","checkpoint = ModelCheckpoint(filepath = CHECKPOINT_FILENAME,\n","                             monitor = 'val_acc',\n","                             verbose = 1,\n","                             save_best_only = True,\n","                             mode = 'max',\n","                             period = 1)\n","\n","\n","CSV_FILENAME = '/'.join([global_variables.OUTPUT_PATH, 'epoch_logfile.csv'])\n","\n","csv_log = CSVLogger(filename = CSV_FILENAME,\n","                    separator = ',',\n","                    append = False)\n","\n","# schedule = StepDecay(initAlpha = 0.01,\n","#                      factor = 0.25, \n","#                      dropEvery = 100)\n","\n","schedule = CyclicLR(base_lr = 1e-7,\n","                    max_lr = 0.001,\n","                    step_size = 200)\n","\n","callbacks = []\n","\n","if not load_from_checkpoint_train:\n","    callbacks = [lr_reduce, early_stop, checkpoint, csv_log, schedule]\n","    #callbacks = [lr_reduce, checkpoint]"]},{"cell_type":"markdown","metadata":{"id":"FQIqe7s8cnSY"},"source":["# Set hyperparameters from training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7i2fQeDucnSY"},"outputs":[],"source":["N_ITERATIONS = int(config['n_iterations'])\n","\n","BATCH_SIZE = int(config['batch_size'])\n","\n","N_BATCHS = int(len(x_train) / BATCH_SIZE)\n","\n","N_EPOCHS = int(N_ITERATIONS / N_BATCHS) #if N_BATCHS != 0 else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bV6EohzRcnSY"},"outputs":[],"source":["# TODO: Jogar em outra função, a do LOGFILE?\n","print(f'\\n[INFO] Hyperparameters from training:\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of iterations: {N_ITERATIONS}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Batch size: {BATCH_SIZE}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of Batchs: {N_BATCHS}\\n', file = global_variables.LOGFILE)\n","\n","print(f'[INFO] Number of Epochs: {N_EPOCHS}\\n', file = global_variables.LOGFILE)\n","\n","print(f'{global_variables.LINE}\\n', file = global_variables.LOGFILE)"]},{"cell_type":"markdown","metadata":{"id":"c1ZFQ_zl0gjk"},"source":["# Data Augmentation\n","## In-place/on-the-fly data augmentation (most common)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDAqVvY60gwZ"},"outputs":[],"source":["datagen = ImageDataGenerator(rotation_range = 20,\n","                              shear_range = 0.15,\n","                              zoom_range = 0.1,\n","                              width_shift_range = 0.2,\n","                              height_shift_range = 0.2,\n","                              horizontal_flip = True,\n","                              fill_mode = 'nearest')\n","                              \n","print(len(datagen.flow(x_train, y_train)))"]},{"cell_type":"markdown","metadata":{"id":"7QQu8TN53H2-"},"source":["# Saving Augmented Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2CeHYUP3HK_"},"outputs":[],"source":["SAVE_AUG_FILE = '/'.join([global_variables.OUTPUT_PATH, 'Augmented Samples'])\n","\n","# Create SAVE_AUG_FILE path if not exists\n","try:\n","    os.makedirs(name = SAVE_AUG_FILE)\n","    print('\\n[INFO]: `SAVE_AUG_FILE` does not exist... creating...')\n","except FileExistsError:\n","    # SAVE_AUG_FILE already exists\n","    pass\n","\n","for x_batch, y_batch in zip(datagen.flow(x_train,\n","                                         y_train,\n","                                         batch_size = 9,\n","                                         save_to_dir = SAVE_AUG_FILE,\n","                                         save_prefix = 'aug', \n","                                         save_format = 'jpg'),\n","                                         range(100)):\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"06ZVtn2UcnSY"},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PP4HRUCc1vR6"},"outputs":[],"source":["# Usarmos fit_generator() ao invés de fit() porque os dados de treinamento vieram de um gerador\n","history = model.fit_generator(datagen.flow(x_train, y_train, batch_size = BATCH_SIZE),\n","                              epochs = N_EPOCHS,\n","                              verbose = 1,\n","                              validation_data = (x_val, y_val),\n","                              validation_steps = len(x_val) // BATCH_SIZE, \n","                              steps_per_epoch = len(x_train) // BATCH_SIZE,\n","                              callbacks = callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZLNq4PNcnSY"},"outputs":[],"source":["# history = training(model = model,\n","#                    X = x_train,\n","#                    Y = y_train,\n","#                    batch_size = BATCH_SIZE,\n","#                    n_epochs = N_EPOCHS,\n","#                    initial_epoch = INIT_EPOCH_TRAIN,\n","#                    X_val = x_val,\n","#                    Y_val = y_val,\n","#                    callbacks = callbacks)"]},{"cell_type":"markdown","metadata":{"id":"XCz34nZ_cnSY"},"source":["# Generating improvement graph at each step of training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Mpr-J9ncnSZ"},"outputs":[],"source":["# en-US default\n","\n","# Use Matplotlib inline\n","%matplotlib inline\n","\n","save_model_accuracy_history(model_history = history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mX8aCwYzcnSZ"},"outputs":[],"source":["# pt-BR\n","\n","# Use Matplotlib inline\n","%matplotlib inline\n","\n","save_model_accuracy_history(model_history = history, language = 'pt-BR')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnE39L4hcnSZ"},"outputs":[],"source":["# en-US default\n","\n","# Use Matplotlib inline\n","%matplotlib inline\n","\n","save_model_loss_history(model_history = history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1kdHPzGcnSZ"},"outputs":[],"source":["# pt-BR\n","\n","# Use Matplotlib inline\n","%matplotlib inline\n","\n","save_model_loss_history(model_history = history,\n","                        language = 'pt-BR')"]},{"cell_type":"markdown","metadata":{"id":"5LYrSdWpcnSZ"},"source":["# Evaluating the model on the test-set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtNrpBE3cnSa"},"outputs":[],"source":["evaluate(model = model,\n","         X = x_test,\n","         Y = y_test,\n","         batch_size = BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"spHg7TfncnSa"},"source":["# Generating output predictions for the input data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4GrwCS1xcnSa"},"outputs":[],"source":["true_y, pred_y = predict(model = model,\n","                         X = x_test,\n","                         Y = y_test,\n","                         batch_size = BATCH_SIZE,\n","                         classes = CLASSES)"]},{"cell_type":"markdown","metadata":{"id":"Vi4x6RbCcnSa"},"source":["# Generating Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J-vrltuKcnSa"},"outputs":[],"source":["if DATASET != 'CIFAR-100' or DATASET != 'ILSVRC-2017':\n","    save_confusion_matrix(y_true = true_y,\n","                          y_pred = pred_y,\n","                          dataset = DATASET,\n","                          classes = CLASSES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmxETZrNcnSa"},"outputs":[],"source":["if DATASET != 'CIFAR-100' or DATASET != 'ILSVRC-2017':\n","    save_confusion_matrix(y_true = true_y,\n","                          y_pred = pred_y,\n","                          dataset = DATASET,\n","                          classes = CLASSES,\n","                          language = 'pt-BR')"]},{"cell_type":"markdown","metadata":{"id":"-donLivHcnSb"},"source":["# Delete Dataset Folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PL-rYopccnSb"},"outputs":[],"source":["if not use_colab:\n","    from shutil import rmtree\n","    rmtree(DATASET, ignore_errors = True)\n","else:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"kHIz8ORwcnSb"},"source":["# Close logfile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v96MQY3YcnSb"},"outputs":[],"source":["close_logfile()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}

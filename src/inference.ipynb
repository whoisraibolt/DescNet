{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ncmeLL1yRPbQ"},"outputs":[],"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","\"\"\"\n","Descriptor Convolutional Neural Network\n","\"\"\"\n","\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"VweLrTjCcnSG"},"source":["# Install packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pvtsU5ZPcnSH"},"outputs":[],"source":["! pip install nvgpu\n","! pip install py-cpuinfo\n","! pip install timer\n","! python -m pip install psutil==5.7.2 --user"]},{"cell_type":"markdown","metadata":{"id":"8N8reeJJ2JgL"},"source":["# Check if is running on Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArncU5zVmQnJ"},"outputs":[],"source":["use_colab = 'google.colab' in str(get_ipython())\n","\n","if use_colab:\n","    # Define base path\n","    BASE_PATH = '/content/gdrive/My Drive/Colab Notebooks/DESC-NET/src/'\n","\n","    # Import Libraries from colab\n","    from google.colab import drive\n","    from google.colab import output\n","    import IPython\n","    \n","    # Mount Google Drive for fast, responsible access to files\n","    drive.mount('/content/gdrive')\n","    \n","    message_use_colab = '[INFO] Running on Colab:\\n'\n","else:\n","    message_use_colab = '[INFO] Not running on Colab:\\n'\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"L2oOq4rC5mxd"},"source":["# Colab Runtime to prevent from disconnecting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOqAfSLG5mxe"},"outputs":[],"source":["if use_colab:\n","    display(IPython.display.Javascript('''\n","    function ClickConnect(){\n","        btn = document.querySelector(\"colab-connect-button\")\n","        if (btn != null){\n","          console.log(\"Click colab-connect-button\"); \n","          btn.click() \n","        }\n","        \n","        btn = document.getElementById('ok')\n","        if (btn != null){\n","          console.log(\"Click reconnect\"); \n","          btn.click() \n","        }\n","      }\n","        \n","    setInterval(ClickConnect, 60000)'''))\n","else:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"dnnzwRnhQ1Ws"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJzUW6P1znzC"},"outputs":[],"source":["from PIL import Image\n","from tensorflow.keras.utils import to_categorical\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, CSVLogger\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import model_from_json\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad\n","from tensorflow.keras.utils import CustomObjectScope\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.metrics import TopKCategoricalAccuracy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import cv2 as cv\n","import glob\n","import json\n","import numpy as np\n","import os\n","import pickle\n","import random\n","import tensorflow as tf\n","import time\n","import timeit\n","import zipfile"]},{"cell_type":"markdown","metadata":{"id":"2GePsfB2Hkx9"},"source":["# Import Custom Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIV2aXEU-6vJ"},"outputs":[],"source":["# To import and use the custom imports, the folder need\n","# to be in se same directory to de file (in colab) \n","if use_colab:\n","    # Unzip in Colab Workspace\n","    UTILITIES = 'utilities.zip'\n","\n","    UTILITIES_PATH =  \"/\".join([BASE_PATH, UTILITIES])\n","\n","    zip_object = zipfile.ZipFile(file = UTILITIES_PATH,\n","                                mode = 'r')\n","\n","    zip_object.extractall()\n","\n","    zip_object.close\n","\n","from utilities.dataset import(#manipulate_pandas,\n","                              create_dataset\n",")\n","\n","from utilities.descriptors import find_detector_or_descriptor\n","\n","from utilities import global_variables\n","\n","from utilities.logfile import(close_logfile,\n","                              open_logfile,\n","                              print_descriptor_initialized_info,\n","                              print_detector_initialized_info,\n","                              print_system_info,\n","                              print_packages_info\n",")\n","\n","from utilities.timer import Timer\n","\n","from utilities.visualizations import(#save_dataset_distribution,\n","                                     save_architecture_visualization,\n","                                     save_model_accuracy_history,\n","                                     save_model_loss_history,\n","                                     save_confusion_matrix,\n",")\n","\n","\n","from utilities.local_feature_detection import local_feature_detection\n","\n","from utilities.local_descriptor_convolution import * # TODO: Arrumar e importar todos... depois...\n","\n","from utilities.residual_neural_network import ResNet\n","\n","from utilities.model_functions import(training,\n","                                      evaluate,\n","                                      predict)"]},{"cell_type":"markdown","metadata":{"id":"7PGZQ1XMJyEZ"},"source":["# Import config.json\n","## Used to load the user configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjznLArrJyRY"},"outputs":[],"source":["if use_colab:\n","    # Unzip in Colab Workspace\n","    JSON = 'config-FEI.zip'\n","\n","    JSON_PATH =  \"/\".join([BASE_PATH, JSON])\n","\n","    zip_object = zipfile.ZipFile(file = JSON_PATH,\n","                                 mode = 'r')\n","\n","    zip_object.extractall()\n","\n","    zip_object.close \n","\n","JSON_PATH = 'config.json'\n","\n","# Load the user configurations\n","with open(JSON_PATH, encoding='utf8') as f:    \n","    config = json.load(f)"]},{"cell_type":"markdown","metadata":{"id":"zb_oM2CYRPbY"},"source":["# Config variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bNeL9qYiRPbY"},"outputs":[],"source":["# Stores the dataset's name\n","DATASET = config['dataset']\n","\n","try:\n","    assert(DATASET == 'MNIST' or\n","           DATASET == 'JAFFE' or\n","           DATASET == 'Extended-CK+' or\n","           DATASET == 'CIFAR-10' or\n","           DATASET == 'CIFAR-100' or\n","           DATASET == 'FEI' or\n","           DATASET == 'FER-2013' or\n","           DATASET == 'ILSVRC-2017')\n","except AssertionError as e:\n","    raise(AssertionError('`DATASET` cannot be different from MNIST or JAFFE or Extended-CK+ or CIFAR-10 or CIFAR-100 or FEI or FER-2013 or ILSVRC-2017'))\n","\n","# Path of training-set\n","DATA_TRAIN_IMAGES = \"/\".join([config['dataset'], config['data_train_images']])\n","\n","# Path of test-set\n","DATA_TEST_IMAGES = \"/\".join([config['dataset'], config['data_test_images']])\n","\n","# Stores the detector's name\n","DETECTOR = config['detector']\n","\n","try:\n","    assert(DETECTOR == 'SIFT' or\n","           DETECTOR == 'SURF' or\n","           DETECTOR == 'KAZE' or\n","           DETECTOR == 'ORB' or\n","           DETECTOR == 'BRISK' or\n","           DETECTOR == 'AKAZE')\n","except AssertionError as e:\n","    raise(AssertionError('`DETECTOR` cannot be different from SIFT or SURF or KAZE or ORB or BRISK or AKAZE'))\n","\n","# Stores the descriptor's name\n","DESCRIPTOR = config['descriptor']\n","\n","try:\n","    assert(DESCRIPTOR == 'SIFT' or\n","           DESCRIPTOR == 'SURF' or\n","           DESCRIPTOR == 'KAZE' or\n","           DESCRIPTOR == 'BRIEF' or\n","           DESCRIPTOR == 'ORB' or\n","           DESCRIPTOR == 'BRISK' or\n","           DESCRIPTOR == 'AKAZE' or\n","           DESCRIPTOR == 'FREAK')\n","except AssertionError as e:\n","    raise(AssertionError('`DESCRIPTOR` cannot be different from SIFT or SURF or KAZE or BRIEF or ORB or BRISK or AKAZE or FREAK'))\n","\n","# Stores the reducer's name\n","#REDUCER = config['reducer']\n","\n","# Stores the architecture's name of CNN\n","ARCHITECTURE = config['architecture']\n","\n","try:\n","    assert(ARCHITECTURE == 'DescNet-50' or\n","           ARCHITECTURE == 'DescNet-101' or\n","           ARCHITECTURE == 'DescNet-152' or\n","           ARCHITECTURE == 'ResNet-50' or\n","           ARCHITECTURE == 'ResNet-101' or\n","           ARCHITECTURE == 'ResNet-152')\n","except AssertionError as e:\n","    raise(AssertionError('`ARCHITECTURE` cannot be different from DescNet-50 or DescNet-101 or DescNet-152 or ResNet-50 or ResNet-101 or ResNet-152'))\n","\n","# Store's desc block if used\n","USE_DESC_BLOCK = config['use_desc_block']\n","\n","# Define base path\n","if not use_colab:\n","    BASE_PATH = config['main_path']\n","    \n","\n","# Path\n","DESCRIPTOR_PATH = \"/\".join([config['dataset'], config['architecture'], config['descriptor']])\n","\n","# Where models are stored\n","MODEL_PATH = \"/\".join([BASE_PATH, 'Models', DESCRIPTOR_PATH])\n","\n","# Stores model data and checkpoints\n","CHECKPOINT_PATH = \"/\".join([BASE_PATH, 'Pretrained', DESCRIPTOR_PATH])"]},{"cell_type":"markdown","metadata":{"id":"dHOeDw5hRPbY"},"source":["# Initializing global variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6J7B6GcyRPbZ"},"outputs":[],"source":["global_variables.initialize()\n","\n","# Simple line to difide dome steps of this project\n","global_variables.LINE\n","\n","# Absolute output path\n","global_variables.OUTPUT_PATH = \"/\".join([BASE_PATH, 'Outputs', DESCRIPTOR_PATH])\n","\n","print(global_variables.OUTPUT_PATH)"]},{"cell_type":"markdown","metadata":{"id":"3lEXPSBopYFJ"},"source":["# Unzip outside Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulosWBTvS4UQ"},"outputs":[],"source":["DATASET_PATH = '/'.join([BASE_PATH, 'Datasets', DATASET + '.zip'])\n","\n","zip_object = zipfile.ZipFile(file = DATASET_PATH,\n","                             mode = 'r')\n","\n","zip_object.extractall('./')\n","\n","zip_object.close"]},{"cell_type":"markdown","metadata":{"id":"wS0yExjKRPbZ"},"source":["# Model Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gVuSPppDRPbZ"},"outputs":[],"source":["# if true, get the last one\n","if len(os.listdir(CHECKPOINT_PATH)) != 0:\n","        # List of files\n","        list_of_files = os.listdir(CHECKPOINT_PATH)\n","\n","        list = []\n","        for file in list_of_files:\n","            list.append('/'.join([CHECKPOINT_PATH, file]))\n","\n","        # Get the last one checkpoint to load and continue from\n","        h5_file = max(list, key = os.path.getmtime)\n","        print(h5_file)\n","\n","json_file = '/'.join([MODEL_PATH, config['architecture'] + '.json'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CJXyU1gBRPbZ"},"outputs":[],"source":["json_file = open(json_file, 'r')\n","\n","loaded_model_json = json_file.read()\n","\n","json_file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hutg1JsLRPbZ"},"outputs":[],"source":["with CustomObjectScope({'DescConv2D': DescConv2D}):\n","    loaded_model = tf.keras.models.load_model(h5_file)"]},{"cell_type":"markdown","metadata":{"id":"ZqH5GCgP_dyl"},"source":["## Carregamento dos dados para gerar a matriz de confusão"]},{"cell_type":"markdown","metadata":{"id":"SIoz-ImKRPbc"},"source":["## Gerando a Matriz de Confusão"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pr-EZ9BtRPbc"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","# Classes info\n","CLASSES = os.listdir(DATA_TRAIN_IMAGES)\n","\n","#load \n","y_true = np.load(global_variables.OUTPUT_PATH + '/y_true.npy')\n","y_pred = np.load(global_variables.OUTPUT_PATH + '/y_pred.npy')\n","\n","# Get the confusion matrix using sklearn\n","cm = confusion_matrix(y_true = y_true, y_pred = y_pred)\n","\n","# Print the confusion matrix as text\n","# print(cm)\n","\n","# Plot the confusion matrix as an image\n","thresh = cm.max() / 2.\n","for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j,\n","             i,\n","             cm[i, j],\n","             horizontalalignment='center',\n","             color='white' if cm[i, j] > thresh else 'black')\n","\n","\n","# Make various adjustments to the plot\n","plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n","plt.colorbar()\n","tick_marks = np.arange(len(CLASSES))\n","plt.xticks(tick_marks, CLASSES, rotation = 45)\n","plt.yticks(tick_marks, CLASSES)\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.savefig(global_variables.OUTPUT_PATH + '/matriz_confusao_mod_alt.png')\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"inference.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}
